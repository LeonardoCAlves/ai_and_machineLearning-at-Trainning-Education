import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Carregando o arquivo de dados
df = pd.read_csv(r"classifica√ß√£o\data\casas.csv")  # L√™ o conjunto de dados salvo anteriormente, que cont√©m informa√ß√µes das casas e suas categorias.

# Separando as vari√°veis independentes (X) e a vari√°vel dependente (y)
X = df.drop(columns=["Pre√ßo", "Categoria"])  # Exclui as colunas 'Pre√ßo' (n√£o relevante para a classifica√ß√£o) e 'Categoria' (vari√°vel alvo).
y = df["Categoria"]  # Define a vari√°vel dependente (alvo) como a coluna 'Categoria', que cont√©m as classes para classifica√ß√£o.

# Dividindo os dados em conjuntos de treino e teste
X_train, X_test, y_train, y_test = train_test_split(
    X, y,                # Divide os dados em vari√°veis independentes e dependente
    test_size=0.3,       # 30% dos dados ser√£o usados como conjunto de teste, 70% para treinamento.
    random_state=42      # Define um valor para garantir reprodutibilidade na divis√£o.
)

'''
random_state:
    Quando trabalhamos com aprendizado de m√°quina, muitas vezes lidamos com processos 
    que envolvem aleatoriedade. Por exemplo:

    Quando dividimos nossos dados em treino e teste, os registros s√£o selecionados de forma aleat√≥ria.
    Modelos como a Random Forest criam v√°rias √°rvores de decis√£o usando amostras aleat√≥rias do conjunto 
    de treinamento.

    Agora, imaginem que a cada vez que rodamos o c√≥digo, o computador escolhe os dados ou as amostras 
    de forma diferente. Isso pode ser um problema porque os resultados v√£o mudar toda vez que rodarmos 
    o modelo. Fica dif√≠cil comparar resultados, corrigir problemas ou explicar o que aconteceu.

    √â a√≠ que entra o random_state. Ele funciona como uma 'semente' que controla a aleatoriedade. 
    'Mesmo que seja aleat√≥rio, fa√ßa sempre do mesmo jeito.' 

    "Voc√™s devem ter reparado que o valor usado no c√≥digo foi 42. Sabem por qu√™? 
    √â uma brincadeira com o livro O Guia do Mochileiro das Gal√°xias, que diz que 42 √© a resposta 
    para a pergunta fundamental da vida, do universo e tudo mais.

    No livro, um supercomputador chamado Pensador Profundo (Deep Thought) √© constru√≠do para responder 
    √† "Pergunta Fundamental da Vida, do Universo e de Tudo". 
    
    Ap√≥s 7,5 milh√µes de anos de c√°lculos, ele finalmente revela que a resposta √©... 42.

    S√≥ que tem um problema: ningu√©m sabe qual √© exatamente a Pergunta Fundamental. 
    Eles pediram a resposta sem entender a pergunta! üòÇ

    Para resolver isso, um outro computador gigante √© constru√≠do: a Terra. 
    Segundo o livro, nosso planeta era, na verdade, um experimento para descobrir essa pergunta, 
    mas foi destru√≠do pelos vogons antes que pud√©ssemos obter o resultado.

'''

'''
    Normalizando os dados num√©ricos
        Se n√£o normalizarmos, essas diferen√ßas de escala podem influenciar o modelo, 
        fazendo com que ele d√™ mais import√¢ncia √†s vari√°veis com valores maiores, 
        mesmo que elas n√£o sejam mais relevantes.    
'''
# Inicializa o escalador padr√£o, que normaliza os dados para ter m√©dia 0 e desvio padr√£o 1.
scaler = StandardScaler()  

'''
    Imagine que voc√™ est√° transformando os dados para uma "escala uniforme", 
    como se estivesse ajustando os ponteiros de um veloc√≠metro, para que ele funcione 
    corretamente independente do carro. 
    
    Essa padroniza√ß√£o ajuda os algoritmos a interpretar 
    as vari√°veis de forma justa, sem dar prioridade indevida a alguma delas.
'''

# Ajusta e transforma os dados de treinamento, e apenas transforma os dados de teste
# Aplica normaliza√ß√£o apenas √†s colunas num√©ricas.
X_train[['Tamanho_m2', 'Quartos', 'Banheiros', 'Idade']] = scaler.fit_transform(
    X_train[['Tamanho_m2', 'Quartos', 'Banheiros', 'Idade']]  
)

# Normaliza as mesmas colunas nos dados de teste usando os par√¢metros ajustados no treino.
X_test[['Tamanho_m2', 'Quartos', 'Banheiros', 'Idade']] = scaler.transform(
    X_test[['Tamanho_m2', 'Quartos', 'Banheiros', 'Idade']]  
)

# Inicializando e treinando o modelo de Random Forest

'''
√Årvores de decis√£o:
    Cada √°rvore de decis√£o √© um modelo que divide os dados em grupos menores com base 
    em perguntas feitas em sequ√™ncia. Por exemplo: "O tamanho da casa √© maior que 100m¬≤?" 
    ou "O n√∫mero de quartos √© maior que 3?"

    Essas perguntas criam ramifica√ß√µes, terminando em previs√µes chamadas folhas.

V√°rios modelos, um s√≥ resultado:
    O Random Forest cria v√°rias √°rvores de decis√£o (da√≠ o "floresta"). 
    Cada √°rvore √© treinada em uma amostra aleat√≥ria dos dados e usa atributos diferentes. 
    Isso introduz varia√ß√£o, reduzindo a chance de "overfitting" 
    (quando o modelo fica bom s√≥ nos dados de treino, mas ruim em novos dados).

Combina√ß√£o dos resultados:
    Ap√≥s treinar todas as √°rvores, o Random Forest faz uma vota√ß√£o: cada √°rvore "vota" 
    na classe que acha correta, e a classe com mais votos √© a previs√£o final.
'''

classifier = RandomForestClassifier(
    n_estimators=100,    # Usa 100 √°rvores de decis√£o na floresta aleat√≥ria.
    random_state=42      # Define um valor fixo para garantir que os resultados sejam reprodut√≠veis.
)
classifier.fit(X_train, y_train)  # Treina o modelo nos dados de treinamento (X_train, y_train).

'''
    Imagine que cada √°rvore de decis√£o √© como um "consultor especialista" 
    em tomar decis√µes com base nos dados. 
    Se voc√™ consulta apenas um especialista, ele pode errar. 
    Mas ao consultar 100 especialistas diferentes, suas chances de tomar a 
    decis√£o correta aumentam, porque o erro de um ser√° compensado pelos outros. 
    
    Essa √© a ideia por tr√°s do Random Forest!

    "Um j√∫ri decidindo um caso, onde cada jurado √© uma √°rvore de decis√£o."
'''


# Fazendo previs√µes no conjunto de teste
y_pred = classifier.predict(X_test)  # Faz previs√µes com base nos dados de teste (X_test).

# Avaliando o modelo
# Calcula a acur√°cia comparando os valores reais (y_test) e previstos (y_pred).
accuracy = accuracy_score(y_test, y_pred)  
print(f"Acur√°cia do modelo de classifica√ß√£o: {accuracy * 100:.2f}%")  # Imprime a acur√°cia do modelo formatada como porcentagem.
